{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChutturiMadhumounika/Labs-fmml/blob/main/FMML_2024_Module_5_Lab_1_NL_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjvepVoWOJU_"
      },
      "source": [
        "#Module 5 Lab 1\n",
        "\n",
        "# Non Linear Support Vector Machines\n",
        "\n",
        "```\n",
        "Module Coordinator : Nikunj Nawal\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVMs Recap:\n",
        "\n",
        "![SVM](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526288453/index3_souoaz.png)\n",
        "\n",
        "SVMs are an iterative approach of trying to find the optimal hyperplane that divides the multidimentional space into different classes present in the dataset.\n",
        "\n",
        "\n",
        "**Hyperplanes:** These are the decision planes that separate the objects of classes that we are trying to classify.\n",
        "\n",
        "**Support Vectors** : Support vectors are the points from dataset that are closest to the hyperplane that divides the dataset.\n",
        "\n",
        "**Margin**:  The gap between the closest support vectors from the different class along the direction perpendicular to the hyperplane. Simply put, it is the sum of perpendicular distance of the support vector of each class to the hyperplane.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "hq4srNYmhMOA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjCAglTcNeGi"
      },
      "source": [
        "# Importing the necessary packages\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "import pandas\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffq0iFPad5dq"
      },
      "source": [
        "The topic of classifier in today's lab, SVMs make for really good linear separators. Let us look at an example which has linearly separable data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "6wSo9Y7DWTth",
        "outputId": "a13797b8-cafc-438c-822e-c1262da83055"
      },
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "ar = np.vstack(     [\\\n",
        "                    np.random.multivariate_normal(np.array([1, 1]), 1.5 * np.array([[2, -1], [-1, 2.0]]), size = 50, ),\\\n",
        "                    np.random.multivariate_normal(np.array([3, 3]), 2 * np.array([[0.75, -0.5], [-0.5, 0.75]]), size = 50, )\n",
        "                    ]\\\n",
        "              )\n",
        "\n",
        "testAr = np.vstack(   [\\\n",
        "                      np.random.multivariate_normal(np.array([1, 1]), np.array([[0.5, -0.25], [-0.25, 0.5]]), size = 500, ),\\\n",
        "                      np.random.multivariate_normal(np.array([3, 3]), np.array([[0.75, -0.5], [-0.5, 0.75]]), size = 500, )\n",
        "                      ]\\\n",
        "                  )\n",
        "testy = np.array([0] * int((testAr.shape[0]/2)) + [1] * int((testAr.shape[0]/2)))\n",
        "\n",
        "X = ar\n",
        "y = np.array([0] * int((ar.shape[0]/2)) + [1] * int((ar.shape[0]/2)))\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "def plotDecisionBoundary(X, y, pair, clf):\n",
        "  x_min, x_max = X[:, pair[0]].min() - 1, X[:, pair[0]].max() + 1\n",
        "  y_min, y_max = X[:, pair[1]].min() - 1, X[:, pair[1]].max() + 1\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
        "                      np.arange(y_min, y_max, 0.1))\n",
        "\n",
        "  y_pred = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "  y_pred = y_pred.reshape(xx.shape)\n",
        "  plt.figure(figsize=(5,4))\n",
        "  plt.contourf(xx, yy, y_pred, alpha=0.4)\n",
        "  plt.scatter(X[:, pair[0]], X[:, pair[1]], c = y, s = 50, edgecolor='k')\n",
        "  plt.legend([\"0\", \"1\"])\n",
        "  plt.gcf().set_dpi(130)\n",
        "  plt.show()\n",
        "\n",
        "def boundaryExp() :\n",
        "  clf = svm.LinearSVC()\n",
        "  pair = [0, 1]\n",
        "  clf.fit(X[:, pair], y)\n",
        "  plotDecisionBoundary(X, y, pair, clf)\n",
        "  plt.show()\n",
        "\n",
        "boundaryExp()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-be3fca840a08>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m ar = np.vstack(     [\\\n\u001b[1;32m      4\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtn7FxSZqRj8"
      },
      "source": [
        "# The Kernel Trick\n",
        "\n",
        "The true potential of SVMs is unleashed when they are combined with kernels.\n",
        "\n",
        "## Kernels : An intuitive explanation\n",
        "\n",
        "Kernel methods are essentially counting on using the training data (say $i^{th}$ example $(x_i, y_i)$ ) itself in a more straightforward way and learning a corresponding weight ($w_i$) for that example. Rather than trying to learn a fixed set of parameters which is done typically.\n",
        "Depending on the kind of kernel used, we can virtually project the training data in a higher dimension to make it easier for the classifier to classify them.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "rpzUIM1ppnxX",
        "outputId": "e7c67ebb-d4e9-43e0-aa82-dd6e1777c0bb"
      },
      "source": [
        "from sklearn.datasets import make_circles\n",
        "X, y = make_circles(200, factor=.1, noise=.1)\n",
        "\n",
        "clf = svm.SVC(kernel='linear').fit(X, y)\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='tab20')\n",
        "plt.gcf().set_dpi(110)\n",
        "plt.legend([\"0\", \"1\"])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'svm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bb81ca7070b4>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_circles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"seaborn-v0_8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'svm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cInt5fSty3w"
      },
      "source": [
        "plt.style.use(\"default\")\n",
        "clf = svm.LinearSVC()\n",
        "pair = [0, 1]\n",
        "clf.fit(X[:, pair], y)\n",
        "plotDecisionBoundary(X, y, [0, 1], clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJaPFAniusEA"
      },
      "source": [
        "However, if we artificially add another dimention to the dataset of the form:\n",
        "\n",
        "$z = x^2 + y^2$\n",
        "we can clearly see a hyperplane that can distinguish both the datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQamaPU8vfIz"
      },
      "source": [
        "Z = np.array([[i[0]**2 + i[1]**2] for i in X])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFi_pqMMvyPS"
      },
      "source": [
        "X_new = np.hstack((X, Z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JuoK_qjwPr_"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "fig = go.Figure(data = [go.Scatter3d(\n",
        "    x = X_new[:, 0],\n",
        "    y = X_new[:, 1],\n",
        "    z = X_new[:, 2],\n",
        "    mode = \"markers\",\n",
        "    marker = {\n",
        "        \"color\" : y,\n",
        "        \"line\": {\"width\" : 4, \"color\":'DarkSlateGrey'},\n",
        "        \"colorscale\": \"viridis\"},\n",
        ")])\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdGH5BF2xuab"
      },
      "source": [
        "That simple trick has helped us to get another dimension in which the data is linearly separable by a hyperplane (in this case, a 2d plane)\n",
        "\n",
        "---\n",
        "\n",
        "Now let us use the rbf kernel and use an SVM Classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybfpMPLFyIiZ"
      },
      "source": [
        "plt.style.use(\"default\")\n",
        "clf = svm.SVC(kernel='rbf')\n",
        "pair = [0, 1]\n",
        "clf.fit(X[:, pair], y)\n",
        "plotDecisionBoundary(X, y, [0, 1], clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHwwqJzHyt23"
      },
      "source": [
        "Now let us get back to our original dataset of iris and see if this kernel trick has helped us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6RS1AGtyfYs"
      },
      "source": [
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
        "clf = svm.SVC(kernel='poly')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy of the decision tree on the test set: \\n\\n{:.3f}\\n\\n\".format(accuracy_score(y_pred, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29evrc-jy0WO"
      },
      "source": [
        "Certainly, using a kernel has increased our accuracy on the iris dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Tasks:\n",
        "\n",
        "Task-1\n",
        "Try to run the same experiment after filtering different features, 2 at a time.\n",
        "\n",
        "Task-2\n",
        "Use different kinds of kernels for the SVM and plot it for Iris dataset -\n",
        "1. linear\n",
        "2. poly\n",
        "3. rbf\n",
        "4. sigmoid\n",
        "5. precomputed\n",
        "\n",
        "Learning Tasks:\n",
        "Learn about SVM types, support vectors and hyperplanes."
      ],
      "metadata": {
        "id": "LteLWVYtYu8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:, :2]  # Taking only the first two features: sepal length and sepal width\n",
        "y = iris.target\n",
        "\n",
        "# For simplicity, we use only two classes in this example for binary classification\n",
        "# This is optional if you want to plot 3D decision boundaries\n",
        "X = X[y != 2]  # Remove class 2\n",
        "y = y[y != 2]  # Remove class 2\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Function to plot decision boundary\n",
        "def plot_decision_boundary(X, y, model, ax):\n",
        "    h = .02  # Step size in the mesh grid\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    ax.contourf(xx, yy, Z, alpha=0.8)\n",
        "    scatter = ax.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o', s=50)\n",
        "    legend1 = ax.legend(*scatter.legend_elements(), title=\"Classes\")\n",
        "    ax.add_artist(legend1)\n",
        "    ax.set_title(model.kernel)\n",
        "\n",
        "# Train different SVM models with various kernels\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "\n",
        "for i, kernel in enumerate(kernels):\n",
        "    model = SVC(kernel=kernel, C=1.0)  # C=1.0 for regularization parameter\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Plot the decision boundary for each kernel\n",
        "    ax = axes[i // 2, i % 2]\n",
        "    plot_decision_boundary(X_train, y_train, model, ax)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XaGYYjZgwToJ"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}